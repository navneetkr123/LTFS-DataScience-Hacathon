{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# please do go through this python notebook: \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "import datetime #Convert to unix time\n",
    "import time #Convert to unix time\n",
    "# if numpy is not installed already : pip3 install numpy\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "# to install xgboost: pip3 install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import pdb\n",
    "import pickle\n",
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules \n",
    "from zipfile import ZipFile \n",
    "  \n",
    "# specifying the zip file name \n",
    "file_name = \"train.zip\"\n",
    "  \n",
    "# opening the zip file in READ mode \n",
    "with ZipFile(file_name, 'r') as zip: \n",
    "    # printing all the contents of the zip file \n",
    "    zip.printdir() \n",
    "  \n",
    "    # extracting all the files \n",
    "    print('Extracting all the files now...') \n",
    "    zip.extractall() \n",
    "    print('Done!') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules \n",
    "from zipfile import ZipFile \n",
    "  \n",
    "# specifying the zip file name \n",
    "file_name = \"test.zip\"\n",
    "  \n",
    "# opening the zip file in READ mode \n",
    "with ZipFile(file_name, 'r') as zip: \n",
    "    # printing all the contents of the zip file \n",
    "    zip.printdir() \n",
    "  \n",
    "    # extracting all the files \n",
    "    print('Extracting all the files now...') \n",
    "    zip.extractall() \n",
    "    print('Done!') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "pos=train_df[train_df.is_chat==1]\n",
    "neg=train_df[train_df.is_chat==0]\n",
    "neg=neg.sample(len(pos))\n",
    "del train_df\n",
    "train_df=pd.concat([pos, neg], sort=False)\n",
    "train_df=train_df.sample(frac=1)\n",
    "del pos, neg\n",
    "train_df =train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape , train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_graph=pd.concat([train[[\"node1_id\", \"node2_id\"]], test[[\"node1_id\", \"node2_id\"]]], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_graph.to_csv('for_graph.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph=nx.read_edgelist(\"for_graph.csv\",delimiter=',',nodetype=int)\n",
    "print(nx.info(train_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for followers\n",
    "def jaccard_for_followers(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.neighbours(a))) == 0  | len(set(g.neighbours(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.neighbors(a)).intersection(set(train_graph.neighbors(b)))))/\\\n",
    "                                 (len(set(train_graph.neighbors(a)).union(set(train_graph.neighbors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['jaccard_common_contact'] = train_df.apply(lambda row:\n",
    "                                            jaccard_for_followers(row['node1_id'],row['node2_id']),axis=1)\n",
    "test_df['jaccard_common_contact'] = test_df.apply(lambda row:\n",
    "                                            jaccard_for_followers(row['node1_id'],row['node2_id']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_for_followers(a,b):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.neighbors(a))) == 0  | len(set(train_graph.neighbors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.neighbors(a)).intersection(set(train_graph.neighbors(b)))))/\\\n",
    "                                     (math.sqrt(len(set(train_graph.neighbors(a))))*(len(set(train_graph.neighbors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_for_followers(2,4702))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['cosine_common_contact'] = train_df.apply(lambda row:\n",
    "                                            cosine_for_followers(row['node1_id'],row['node2_id']),axis=1)\n",
    "test_df['cosine_common_contact'] = test_df.apply(lambda row:\n",
    "                                            cosine_for_followers(row['node1_id'],row['node2_id']),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating no of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source and destination\n",
    "    \n",
    "    inter_followers=[]\n",
    "    \n",
    "    for i,row in df_final.iterrows():\n",
    "        try:\n",
    "            s1=set(train_graph.neighbors(row['node1_id']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "        try:\n",
    "            d1=set(train_graph.neighbors(row['node2_id']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "        \n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "\n",
    "    return inter_followers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['common_contact']= compute_features_stage1(train_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df['common_contact']= compute_features_stage1(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"n1_tot_contact\"] = train_df[\"node1_id\"].apply(lambda x:len(set(train_graph.neighbors(x))))\n",
    "test_df[\"n1_tot_contact\"] = test_df[\"node1_id\"].apply(lambda x:len(set(train_graph.neighbors(x))))\n",
    "    \n",
    "train_df[\"n2_tot_contact\"] = train_df[\"node2_id\"].apply(lambda x:len(set(train_graph.neighbors(x))))\n",
    "test_df[\"n2_tot_contact\"] = test_df[\"node2_id\"].apply(lambda x:len(set(train_graph.neighbors(x))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if has direct edge then deleting that edge and calculating shortest path\n",
    "def compute_shortest_path_length(a,b):\n",
    "    p=-1\n",
    "    try:\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "compute_shortest_path_length(77697, 826021)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#mapping shortest path on train \n",
    "train_df['shortest_path'] = train_df.apply(lambda row: compute_shortest_path_length(row['node1_id'],row['node2_id']),axis=1)\n",
    "#mapping shortest path on test\n",
    "test_df['shortest_path'] = test_df.apply(lambda row: compute_shortest_path_length(row['node1_id'],row['node2_id']),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adar index\n",
    "def calc_adar_in(a,b):\n",
    "    sum=0\n",
    "    try:\n",
    "        n=list(set(train_graph.neighbors(a)).intersection(set(train_graph.neighbors(b))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log1p(len(list(train_graph.neighbors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_adar_in(1,189226)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['calc_adar_in'] = train_df.apply(lambda row: calc_adar_in(row['node1_id'],row['node2_id']),axis=1)\n",
    "#mapping adar index on test\n",
    "test_df['calc_adar_in'] = test_df.apply(lambda row: calc_adar_in(row['node1_id'],row['node2_id']),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight for source and destination of each link\n",
    "Weight_in = {}\n",
    "Weight_out = {}\n",
    "for i in  tqdm(train_graph.nodes()):\n",
    "    s1=set(train_graph.neighbors(i))\n",
    "    w_in = 1.0/(np.sqrt(1+len(s1)))\n",
    "    Weight_in[i]=w_in\n",
    "    \n",
    "    s2=set(train_graph.neighbors(i))\n",
    "    w_out = 1.0/(np.sqrt(1+len(s2)))\n",
    "    Weight_out[i]=w_out\n",
    "    \n",
    "#for imputing with mean\n",
    "mean_weight_in = np.mean(list(Weight_in.values()))\n",
    "mean_weight_out = np.mean(list(Weight_out.values()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " #mapping to pandas train\n",
    "train_df['weight_n1'] = train_df.node1_id.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "train_df['weight_n2'] = train_df.node2_id.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "#mapping to pandas test\n",
    "test_df['weight_n1'] = test_df.node1_id.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "test_df['weight_n2'] = test_df.node2_id.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hdf = HDFStore('train_test_undirect_graph.h5')\n",
    "hdf.put('train_df',train_df, format='table', data_columns=True)\n",
    "hdf.put('test_df',test_df, format='table', data_columns=True)\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"train_test_undirect_graph.h5\"):\n",
    "    \n",
    "    train_df['jaccard_common_contact'] = train_df.apply(lambda row:\n",
    "                                            jaccard_for_followers(row['node1_id'],row['node2_id']),axis=1)\n",
    "    test_df['jaccard_common_contact'] = test_df.apply(lambda row:\n",
    "                                            jaccard_for_followers(row['node1_id'],row['node2_id']),axis=1)\n",
    "    \n",
    "    train_df['cosine_common_contact'] = train_df.apply(lambda row:\n",
    "                                            cosine_for_followers(row['node1_id'],row['node2_id']),axis=1)\n",
    "    test_df['cosine_common_contact'] = test_df.apply(lambda row:\n",
    "                                            cosine_for_followers(row['node1_id'],row['node2_id']),axis=1)\n",
    "\n",
    "    \n",
    "    train_df['common_contact']= compute_features_stage1(train_df)\n",
    "    test_df['common_contact']= compute_features_stage1(test_df)\n",
    "    \n",
    "    train_df[\"n1_tot_contact\"] = train_df[\"node1_id\"].apply(lambda x:len(set(train_graph.neighbors(x))))\n",
    "    test_df[\"n1_tot_contact\"] = test_df[\"node1_id\"].apply(lambda x:len(set(train_graph.neighbors(x))))\n",
    "    \n",
    "    train_df[\"n2_tot_contact\"] = train_df[\"node2_id\"].apply(lambda x:len(set(train_graph.neighbors(x))))\n",
    "    test_df[\"n2_tot_contact\"] = test_df[\"node2_id\"].apply(lambda x:len(set(train_graph.neighbors(x))))\n",
    "    \n",
    "    \n",
    "    #mapping shortest path on train \n",
    "    train_df['shortest_path'] = train_df.apply(lambda row: compute_shortest_path_length(row['node1_id'],row['node2_id']),axis=1)\n",
    "    #mapping shortest path on test\n",
    "    test_df['shortest_path'] = test_df.apply(lambda row: compute_shortest_path_length(row['node1_id'],row['node2_id']),axis=1)\n",
    "\n",
    "    train_df['calc_adar_in'] = train_df.apply(lambda row: calc_adar_in(row['node1_id'],row['node2_id']),axis=1)\n",
    "    #mapping adar index on test\n",
    "    test_df['calc_adar_in'] = test_df.apply(lambda row: calc_adar_in(row['node1_id'],row['node2_id']),axis=1)\n",
    "    \n",
    "    #mapping to pandas train\n",
    "    train_df['weight_n1'] = train_df.node1_id.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "    train_df['weight_n2'] = train_df.node2_id.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "    #mapping to pandas test\n",
    "    test_df['weight_n1'] = test_df.node1_id.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "    test_df['weight_n2'] = test_df.node2_id.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "    hdf = HDFStore('train_test_undirect_graph.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    train_df = read_hdf('train_test_undirect_graph.h5', 'train_df',mode='r')\n",
    "    test_df = read_hdf('train_test_undirect_graph.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# please do go through this python notebook: \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "import datetime #Convert to unix time\n",
    "import time #Convert to unix time\n",
    "# if numpy is not installed already : pip3 install numpy\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "# to install xgboost: pip3 install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import pdb\n",
    "import pickle\n",
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#reading\n",
    "from pandas import read_hdf\n",
    "train_df = read_hdf('train_test_undirect_graph.h5', 'train_df',mode='r')\n",
    "test_df = read_hdf('train_test_undirect_graph.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def follows_back(a,b):\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_back(1,189226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('train_test_undirect_graph_follows.h5'):\n",
    "#mapping followback or not on train\n",
    "    train_df['follows_back'] = train_df.apply(lambda row: follows_back(row['node1_id'],row['node2_id']),axis=1)\n",
    "\n",
    "#mapping followback or not on test\n",
    "    test_df['follows_back'] = test_df.apply(lambda row: follows_back(row['node1_id'],row['node2_id']),axis=1)\n",
    "    \n",
    "    hdf = HDFStore('train_test_undirect_graph_follows.h5')\n",
    "    hdf.put('train_df',train_df, format='table', data_columns=True)\n",
    "    hdf.put('test_df',test_df, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    train_df = read_hdf('train_test_undirect_graph_follows.h5', 'train_df',mode='r')\n",
    "    test_df = read_hdf('train_test_undirect_graph_follows.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6755352, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node1_id', 'node2_id', 'is_chat', 'jaccard_common_contact',\n",
       "       'cosine_common_contact', 'total_common', 'n1_tot_contact',\n",
       "       'n2_tot_contact', 'shortest_path', 'calc_adar_in', 'weight_n1',\n",
       "       'weight_n2', 'follows_back'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=pd.read_csv(\"user_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, feature, how='left', left_on='node2_id', right_on='node_id')\n",
    "del train_df[\"node_id\"]\n",
    "train_df=train_df.rename(index=str, columns={\"f1\":\"n1_f1\", \"f2\":'n1_f2',\"f3\":'n1_f3',\"f4\":'n1_f4',\"f5\":'n1_f5',\"f6\":'n1_f6',\\\n",
    "                                            \"f7\":'n1_f7',\"f8\":'n1_f8',\"f9\":'n1_f9',\"f10\":'n1_f10',\"f11\":'n1_f11',\\\n",
    "                                            \"f12\":'n1_f12',\"f13\":'n1_f13'})\n",
    "\n",
    "train_df = pd.merge(train_df, feature, how='left', left_on='node1_id', right_on='node_id')\n",
    "del train_df[\"node_id\"]\n",
    "train_df=train_df.rename(index=str, columns={\"f1\":\"n2_f1\", \"f2\":'n2_f2',\"f3\":'n2_f3',\"f4\":'n2_f4',\"f5\":'n2_f5',\"f6\":'n2_f6',\\\n",
    "                                            \"f7\":'n2_f7',\"f8\":'n2_f8',\"f9\":'n2_f9',\"f10\":'n2_f10',\"f11\":'n2_f11',\\\n",
    "                                            \"f12\":'n2_f12',\"f13\":'n2_f13'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test_df, feature, how='left', left_on='node2_id', right_on='node_id')\n",
    "del test_df[\"node_id\"]\n",
    "test_df=test_df.rename(index=str, columns={\"f1\":\"n1_f1\", \"f2\":'n1_f2',\"f3\":'n1_f3',\"f4\":'n1_f4',\"f5\":'n1_f5',\"f6\":'n1_f6',\\\n",
    "                                            \"f7\":'n1_f7',\"f8\":'n1_f8',\"f9\":'n1_f9',\"f10\":'n1_f10',\"f11\":'n1_f11',\\\n",
    "                                            \"f12\":'n1_f12',\"f13\":'n1_f13'})\n",
    "\n",
    "test_df = pd.merge(test_df, feature, how='left', left_on='node1_id', right_on='node_id')\n",
    "del test_df[\"node_id\"]\n",
    "test_df=test_df.rename(index=str, columns={\"f1\":\"n2_f1\", \"f2\":'n2_f2',\"f3\":'n2_f3',\"f4\":'n2_f4',\"f5\":'n2_f5',\"f6\":'n2_f6',\\\n",
    "                                            \"f7\":'n2_f7',\"f8\":'n2_f8',\"f9\":'n2_f9',\"f10\":'n2_f10',\"f11\":'n2_f11',\\\n",
    "                                            \"f12\":'n2_f12',\"f13\":'n2_f13'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1_id</th>\n",
       "      <th>node2_id</th>\n",
       "      <th>is_chat</th>\n",
       "      <th>jaccard_common_contact</th>\n",
       "      <th>cosine_common_contact</th>\n",
       "      <th>total_common</th>\n",
       "      <th>n1_tot_contact</th>\n",
       "      <th>n2_tot_contact</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>calc_adar_in</th>\n",
       "      <th>...</th>\n",
       "      <th>n2_f4</th>\n",
       "      <th>n2_f5</th>\n",
       "      <th>n2_f6</th>\n",
       "      <th>n2_f7</th>\n",
       "      <th>n2_f8</th>\n",
       "      <th>n2_f9</th>\n",
       "      <th>n2_f10</th>\n",
       "      <th>n2_f11</th>\n",
       "      <th>n2_f12</th>\n",
       "      <th>n2_f13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6542909</td>\n",
       "      <td>5443649</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1.425150</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2768271</td>\n",
       "      <td>3512596</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1.281474</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   node1_id  node2_id  is_chat  jaccard_common_contact  cosine_common_contact  \\\n",
       "0   6542909   5443649        0                0.036364                      0   \n",
       "1   2768271   3512596        0                0.040816                      0   \n",
       "\n",
       "   total_common  n1_tot_contact  n2_tot_contact  shortest_path  calc_adar_in  \\\n",
       "0             2              18              39              2      1.425150   \n",
       "1             2              39              12              2      1.281474   \n",
       "\n",
       "   ...  n2_f4  n2_f5  n2_f6  n2_f7  n2_f8  n2_f9  n2_f10  n2_f11  n2_f12  \\\n",
       "0  ...     31      0      0     31      1      0      31       1       0   \n",
       "1  ...      3      1      0      9      1      0      16       1       0   \n",
       "\n",
       "   n2_f13  \n",
       "0      15  \n",
       "1      15  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.head(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>node1_id</th>\n",
       "      <th>node2_id</th>\n",
       "      <th>jaccard_common_contact</th>\n",
       "      <th>cosine_common_contact</th>\n",
       "      <th>total_common</th>\n",
       "      <th>n1_tot_contact</th>\n",
       "      <th>n2_tot_contact</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>calc_adar_in</th>\n",
       "      <th>...</th>\n",
       "      <th>n2_f4</th>\n",
       "      <th>n2_f5</th>\n",
       "      <th>n2_f6</th>\n",
       "      <th>n2_f7</th>\n",
       "      <th>n2_f8</th>\n",
       "      <th>n2_f9</th>\n",
       "      <th>n2_f10</th>\n",
       "      <th>n2_f11</th>\n",
       "      <th>n2_f12</th>\n",
       "      <th>n2_f13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7107094</td>\n",
       "      <td>8010772</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1.307276</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7995251</td>\n",
       "      <td>2805801</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>2.227250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  node1_id  node2_id  jaccard_common_contact  cosine_common_contact  \\\n",
       "0   1   7107094   8010772                0.027027                      0   \n",
       "1   2   7995251   2805801                0.041237                      0   \n",
       "\n",
       "   total_common  n1_tot_contact  n2_tot_contact  shortest_path  calc_adar_in  \\\n",
       "0             2              52              24              2      1.307276   \n",
       "1             4              45              56              4      2.227250   \n",
       "\n",
       "   ...  n2_f4  n2_f5  n2_f6  n2_f7  n2_f8  n2_f9  n2_f10  n2_f11  n2_f12  \\\n",
       "0  ...     31      6      1     31      8      1      31       9       1   \n",
       "1  ...      0      0      0      0      0      0       6       0       0   \n",
       "\n",
       "   n2_f13  \n",
       "0      15  \n",
       "1       7  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex=[\"is_chat\", \"id\", \"node1_id\", \"node2_id\"]\n",
    "target=train_df[\"is_chat\"]\n",
    "features=[col for col in train_df if col not in ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.91 µs\n",
      "Training until validation scores don't improve for 2000 rounds.\n",
      "[1000]\ttraining's auc: 0.883799\tvalid_1's auc: 0.872936\n",
      "[2000]\ttraining's auc: 0.894194\tvalid_1's auc: 0.873088\n",
      "[3000]\ttraining's auc: 0.902613\tvalid_1's auc: 0.872787\n",
      "Early stopping, best iteration is:\n",
      "[1714]\ttraining's auc: 0.891469\tvalid_1's auc: 0.873226\n",
      "Training until validation scores don't improve for 2000 rounds.\n",
      "[1000]\ttraining's auc: 0.884338\tvalid_1's auc: 0.872459\n",
      "[2000]\ttraining's auc: 0.894374\tvalid_1's auc: 0.872632\n",
      "[3000]\ttraining's auc: 0.902836\tvalid_1's auc: 0.872383\n",
      "Early stopping, best iteration is:\n",
      "[1640]\ttraining's auc: 0.891016\tvalid_1's auc: 0.872693\n",
      "Training until validation scores don't improve for 2000 rounds.\n",
      "[1000]\ttraining's auc: 0.884073\tvalid_1's auc: 0.87237\n",
      "[2000]\ttraining's auc: 0.894129\tvalid_1's auc: 0.872524\n",
      "[3000]\ttraining's auc: 0.902654\tvalid_1's auc: 0.872156\n",
      "Early stopping, best iteration is:\n",
      "[1767]\ttraining's auc: 0.891883\tvalid_1's auc: 0.872699\n",
      "cv score: 0.87287 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "%time\n",
    "skf=StratifiedKFold(n_splits=3, shuffle=True, random_state=2019)\n",
    "oof=np.zeros(len(train_df))\n",
    "predictions=np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "param = {\"objective\":\"binary\",\n",
    "         \"boost\":\"gbdt\",\n",
    "         \"metric\":\"auc\",\n",
    "         \"learning_rate\":0.1,\n",
    "         \"num_leaves\":12,\n",
    "         \"max_depth\":-1,\n",
    "         \"tree_learner\":\"serial\",\n",
    "         #\"feature_fraction\":0.4,\n",
    "         #\"bagging_freq\":5,\n",
    "         #\"bagging_fraction\":0.4,\n",
    "         \"min_data_in_leaf\":60,\n",
    "         \"min_sum_hessian_in_leaf\":10,\n",
    "         \"n_jobs\":-1,\n",
    "         }\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(train_df.values , target.values )):\n",
    "    #print(\"fold n{}\".format(fold_))\n",
    "    \n",
    "    trn_data = lgb.Dataset(train_df[features].iloc[trn_idx], label = target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df[features].iloc[val_idx], label = target.iloc[val_idx])\n",
    "    \n",
    "    num_round = 1000000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval = 1000, early_stopping_rounds=2000)\n",
    "    oof[val_idx] = clf.predict(train_df[features].iloc[val_idx], num_iteration = clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"]=features\n",
    "    fold_importance_df[\"importance\"]=clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"]=fold_+1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions+=clf.predict(test_df[features], num_iteration = clf.best_iteration)/skf.n_splits\n",
    "    \n",
    "feature_importance_df = feature_importance_df[[\"feature\", 'importance']].groupby(\"feature\").mean().sort_values(by = \"importance\", ascending=2000)    \n",
    "print(\"cv score: {:<8.5f}\".format(roc_auc_score(target, oof)))    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2=pd.DataFrame({\"id\":test_df[\"id\"], \"is_chat\":predictions})\n",
    "result_2.to_csv(\"result_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
